{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook overview\n",
    "- Goal: train a tiny, streaming pitch‑correction model that predicts per‑frame shift (cents) and a confidence.\n",
    "- Strategy: build labels from a teacher (pYIN → low‑pass trend → hysteretic semitone snap), train a causal TCN on log‑mel features, export to int8 TFLite.\n",
    "- Sections:\n",
    "  1) Imports & config  \n",
    "  2) Data windowing/normalization \n",
    "  3) Causal TCN\n",
    "  4) Training (losses/callbacks)  \n",
    "  5) Streaming emulator  \n",
    "  6) SavedModel → TFLite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full melody config: {'n_mels': 32, 'fps': 100, 'window': 40}\n"
     ]
    }
   ],
   "source": [
    "# Full Melody Pitch Correction (Causal TCN, Streaming)\n",
    "\n",
    "# 1) Imports & Config\n",
    "import os, json, glob, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# directories for data access and artifacts\n",
    "ROOT = Path(\"/Users/brandontsai/ESE3600/tinymlpitchcorrection\")\n",
    "PROC_DIR = ROOT / \"data/processed/features\"\n",
    "META_DIR = ROOT / \"metadata\"\n",
    "OUT_DIR = ROOT / \"artifacts/full\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "N_MELS = 32 \n",
    "WINDOW = 40 # fixed window length for model input (frames)\n",
    "\n",
    "with open(META_DIR / \"feature_norm.json\", \"r\") as f:\n",
    "    norm = json.load(f)\n",
    "# Load full norm stats but slice to N_MELS\n",
    "FEATURE_MEAN = np.array(norm[\"feature_mean\"][:N_MELS] or [0.0]*N_MELS, dtype=np.float32)\n",
    "FEATURE_STD = np.array(norm[\"feature_std\"][:N_MELS] or [1.0]*N_MELS, dtype=np.float32)\n",
    "FPS = norm.get(\"frames_per_second\", 100)\n",
    "\n",
    "SHIFT_RANGE_CENTS = 300.0 # represents the range of possible pitch shifts\n",
    "\n",
    "random.seed(13)\n",
    "np.random.seed(13)\n",
    "tf.random.set_seed(13)\n",
    "print(\"Full melody config:\", dict(n_mels=N_MELS, fps=FPS, window=WINDOW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (20888, 40, 32) (20888, 40, 1) (429, 40, 32) (429, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "# 2) Data loading (all categories), windowing, normalization\n",
    "\n",
    "def list_npz(split):\n",
    "    return sorted(glob.glob(str(PROC_DIR / split / '*.npz')))\n",
    "\n",
    "\n",
    "def normalize_features(x):\n",
    "    return (x[:, :N_MELS] - FEATURE_MEAN[None, :]) / (FEATURE_STD[None, :] + 1e-8)\n",
    "\n",
    "\n",
    "# makes sequences of features and targets\n",
    "def make_sequences(npz_paths, T=120, stride=60, limit=None):\n",
    "    xs, ys = [], []\n",
    "    count = 0\n",
    "    for p in npz_paths:\n",
    "        arr = np.load(p)\n",
    "        logmel = normalize_features(arr['logmel'].astype(np.float32))\n",
    "        target_shift = arr['target_shift'].astype(np.float32)\n",
    "        L = len(target_shift)\n",
    "        i = 0\n",
    "        while i + T <= L:\n",
    "            xs.append(logmel[i:i+T])\n",
    "            ys.append(target_shift[i:i+T, None])\n",
    "            i += stride\n",
    "            count += 1\n",
    "            if limit and count >= limit:\n",
    "                break\n",
    "        if limit and count >= limit:\n",
    "            break\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "train_files = list_npz('train')\n",
    "val_files = list_npz('val')\n",
    "X_train, y_train = make_sequences(train_files, T=120, stride=60)\n",
    "X_val, y_val = make_sequences(val_files, T=120, stride=60)\n",
    "print('Shapes:', X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "\n",
    "BATCH=32\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(4096).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ features            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │ conv1d_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ conv1d_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ conv1d_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │ add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ conv1d_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │ add_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ conv1d_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ add_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ add_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ shift_cents         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ conv1d_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ confidence (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ conv1d_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ features            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_80 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m1,056\u001b[0m │ features[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_81 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m3,104\u001b[0m │ conv1d_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_82 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m1,056\u001b[0m │ conv1d_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_30 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ conv1d_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_83 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m3,104\u001b[0m │ add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_84 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m1,056\u001b[0m │ conv1d_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_31 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_85 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m3,104\u001b[0m │ add_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_86 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m1,056\u001b[0m │ conv1d_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_32 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ add_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_87 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m1,056\u001b[0m │ add_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ shift_cents         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │         \u001b[38;5;34m33\u001b[0m │ conv1d_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mConv1D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ confidence (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │         \u001b[38;5;34m33\u001b[0m │ conv1d_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,658</span> (57.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,658\u001b[0m (57.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,658</span> (57.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,658\u001b[0m (57.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3) Causal TCN with dilations (causal Conv1D blocks)\n",
    "from tensorflow.keras import layers as L, models\n",
    "\n",
    "INPUT_DIM = N_MELS\n",
    "\n",
    "# Use fixed-length window as model input to avoid dynamic 'same' padding math (FloorMod)\n",
    "inp = L.Input(shape=(WINDOW, INPUT_DIM), name='features')\n",
    "x = L.Conv1D(32, 1, padding='same', activation='relu')(inp)\n",
    "\n",
    "# Residual dilated blocks (use Conv1D with padding='same' now that input length is fixed)\n",
    "for d in [1, 2, 4]:\n",
    "    res = x\n",
    "    x = L.Conv1D(32, 3, dilation_rate=d, padding='same', activation=None)(x)\n",
    "    x = L.Conv1D(32, 1, activation='relu')(x)\n",
    "    x = L.Add()([x, res])\n",
    "\n",
    "x = L.Conv1D(32, 1, activation='relu')(x)\n",
    "shift = L.Conv1D(1, 1, activation=None, name='shift_cents')(x)\n",
    "conf = L.Conv1D(1, 1, activation='sigmoid', name='confidence')(x)\n",
    "\n",
    "model = models.Model(inputs=inp, outputs=[shift, conf])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss={'shift_cents':'mae','confidence':'binary_crossentropy'},\n",
    "    loss_weights={'shift_cents':1.0,'confidence':0.01},\n",
    "    metrics={'shift_cents':'mae'}\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - confidence_loss: 0.0934 - loss: 14.8949 - shift_cents_loss: 14.8951 - shift_cents_mae: 14.8940 - val_confidence_loss: 0.0088 - val_loss: 12.9071 - val_shift_cents_loss: 13.4429 - val_shift_cents_mae: 12.9070 - learning_rate: 0.0010\n",
      "Epoch 2/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - confidence_loss: 0.0934 - loss: 14.8949 - shift_cents_loss: 14.8951 - shift_cents_mae: 14.8940 - val_confidence_loss: 0.0088 - val_loss: 12.9071 - val_shift_cents_loss: 13.4429 - val_shift_cents_mae: 12.9070 - learning_rate: 0.0010\n",
      "Epoch 2/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 0.0058 - loss: 14.6303 - shift_cents_loss: 14.6314 - shift_cents_mae: 14.6302 - val_confidence_loss: 0.0033 - val_loss: 12.5696 - val_shift_cents_loss: 13.1413 - val_shift_cents_mae: 12.5696 - learning_rate: 0.0010\n",
      "Epoch 3/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 0.0058 - loss: 14.6303 - shift_cents_loss: 14.6314 - shift_cents_mae: 14.6302 - val_confidence_loss: 0.0033 - val_loss: 12.5696 - val_shift_cents_loss: 13.1413 - val_shift_cents_mae: 12.5696 - learning_rate: 0.0010\n",
      "Epoch 3/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 0.0034 - loss: 14.5074 - shift_cents_loss: 14.5119 - shift_cents_mae: 14.5073 - val_confidence_loss: 6.0622e-04 - val_loss: 12.2396 - val_shift_cents_loss: 12.7953 - val_shift_cents_mae: 12.2396 - learning_rate: 0.0010\n",
      "Epoch 4/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 0.0034 - loss: 14.5074 - shift_cents_loss: 14.5119 - shift_cents_mae: 14.5073 - val_confidence_loss: 6.0622e-04 - val_loss: 12.2396 - val_shift_cents_loss: 12.7953 - val_shift_cents_mae: 12.2396 - learning_rate: 0.0010\n",
      "Epoch 4/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - confidence_loss: 0.0015 - loss: 14.3827 - shift_cents_loss: 14.3854 - shift_cents_mae: 14.3827 - val_confidence_loss: 2.7814e-04 - val_loss: 11.9239 - val_shift_cents_loss: 12.5168 - val_shift_cents_mae: 11.9239 - learning_rate: 0.0010\n",
      "Epoch 5/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - confidence_loss: 0.0015 - loss: 14.3827 - shift_cents_loss: 14.3854 - shift_cents_mae: 14.3827 - val_confidence_loss: 2.7814e-04 - val_loss: 11.9239 - val_shift_cents_loss: 12.5168 - val_shift_cents_mae: 11.9239 - learning_rate: 0.0010\n",
      "Epoch 5/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 8.8065e-04 - loss: 14.3042 - shift_cents_loss: 14.3056 - shift_cents_mae: 14.3042 - val_confidence_loss: 2.2985e-04 - val_loss: 11.6775 - val_shift_cents_loss: 12.2471 - val_shift_cents_mae: 11.6775 - learning_rate: 0.0010\n",
      "Epoch 6/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 8.8065e-04 - loss: 14.3042 - shift_cents_loss: 14.3056 - shift_cents_mae: 14.3042 - val_confidence_loss: 2.2985e-04 - val_loss: 11.6775 - val_shift_cents_loss: 12.2471 - val_shift_cents_mae: 11.6775 - learning_rate: 0.0010\n",
      "Epoch 6/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 3.9736e-04 - loss: 14.2052 - shift_cents_loss: 14.2073 - shift_cents_mae: 14.2052 - val_confidence_loss: 6.6073e-05 - val_loss: 11.8199 - val_shift_cents_loss: 12.3925 - val_shift_cents_mae: 11.8199 - learning_rate: 0.0010\n",
      "Epoch 7/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 3.9736e-04 - loss: 14.2052 - shift_cents_loss: 14.2073 - shift_cents_mae: 14.2052 - val_confidence_loss: 6.6073e-05 - val_loss: 11.8199 - val_shift_cents_loss: 12.3925 - val_shift_cents_mae: 11.8199 - learning_rate: 0.0010\n",
      "Epoch 7/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 1.9499e-04 - loss: 14.1266 - shift_cents_loss: 14.1276 - shift_cents_mae: 14.1266 - val_confidence_loss: 2.8160e-05 - val_loss: 11.2627 - val_shift_cents_loss: 11.8538 - val_shift_cents_mae: 11.2627 - learning_rate: 0.0010\n",
      "Epoch 8/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 1.9499e-04 - loss: 14.1266 - shift_cents_loss: 14.1276 - shift_cents_mae: 14.1266 - val_confidence_loss: 2.8160e-05 - val_loss: 11.2627 - val_shift_cents_loss: 11.8538 - val_shift_cents_mae: 11.2627 - learning_rate: 0.0010\n",
      "Epoch 8/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 9.5219e-05 - loss: 14.0385 - shift_cents_loss: 14.0396 - shift_cents_mae: 14.0385 - val_confidence_loss: 1.5327e-05 - val_loss: 11.4457 - val_shift_cents_loss: 11.9858 - val_shift_cents_mae: 11.4457 - learning_rate: 0.0010\n",
      "Epoch 9/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 9.5219e-05 - loss: 14.0385 - shift_cents_loss: 14.0396 - shift_cents_mae: 14.0385 - val_confidence_loss: 1.5327e-05 - val_loss: 11.4457 - val_shift_cents_loss: 11.9858 - val_shift_cents_mae: 11.4457 - learning_rate: 0.0010\n",
      "Epoch 9/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 4.3450e-05 - loss: 13.9536 - shift_cents_loss: 13.9550 - shift_cents_mae: 13.9536 - val_confidence_loss: 4.6796e-06 - val_loss: 11.1401 - val_shift_cents_loss: 11.7271 - val_shift_cents_mae: 11.1401 - learning_rate: 0.0010\n",
      "Epoch 10/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 4.3450e-05 - loss: 13.9536 - shift_cents_loss: 13.9550 - shift_cents_mae: 13.9536 - val_confidence_loss: 4.6796e-06 - val_loss: 11.1401 - val_shift_cents_loss: 11.7271 - val_shift_cents_mae: 11.1401 - learning_rate: 0.0010\n",
      "Epoch 10/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 2.9762e-05 - loss: 13.9023 - shift_cents_loss: 13.9043 - shift_cents_mae: 13.9023 - val_confidence_loss: 5.3623e-06 - val_loss: 11.9117 - val_shift_cents_loss: 12.5046 - val_shift_cents_mae: 11.9117 - learning_rate: 0.0010\n",
      "Epoch 11/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 2.9762e-05 - loss: 13.9023 - shift_cents_loss: 13.9043 - shift_cents_mae: 13.9023 - val_confidence_loss: 5.3623e-06 - val_loss: 11.9117 - val_shift_cents_loss: 12.5046 - val_shift_cents_mae: 11.9117 - learning_rate: 0.0010\n",
      "Epoch 11/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 3.0943e-05 - loss: 13.7990 - shift_cents_loss: 13.8005 - shift_cents_mae: 13.7990 - val_confidence_loss: 5.1261e-06 - val_loss: 11.1131 - val_shift_cents_loss: 11.6776 - val_shift_cents_mae: 11.1131 - learning_rate: 0.0010\n",
      "Epoch 12/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 3.0943e-05 - loss: 13.7990 - shift_cents_loss: 13.8005 - shift_cents_mae: 13.7990 - val_confidence_loss: 5.1261e-06 - val_loss: 11.1131 - val_shift_cents_loss: 11.6776 - val_shift_cents_mae: 11.1131 - learning_rate: 0.0010\n",
      "Epoch 12/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 2.3759e-05 - loss: 13.7614 - shift_cents_loss: 13.7616 - shift_cents_mae: 13.7614 - val_confidence_loss: 1.7713e-06 - val_loss: 10.7187 - val_shift_cents_loss: 11.2148 - val_shift_cents_mae: 10.7187 - learning_rate: 0.0010\n",
      "Epoch 13/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 2.3759e-05 - loss: 13.7614 - shift_cents_loss: 13.7616 - shift_cents_mae: 13.7614 - val_confidence_loss: 1.7713e-06 - val_loss: 10.7187 - val_shift_cents_loss: 11.2148 - val_shift_cents_mae: 10.7187 - learning_rate: 0.0010\n",
      "Epoch 13/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 1.9670e-05 - loss: 13.6902 - shift_cents_loss: 13.6923 - shift_cents_mae: 13.6902 - val_confidence_loss: 7.3674e-06 - val_loss: 11.0834 - val_shift_cents_loss: 11.5728 - val_shift_cents_mae: 11.0834 - learning_rate: 0.0010\n",
      "Epoch 14/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 1.9670e-05 - loss: 13.6902 - shift_cents_loss: 13.6923 - shift_cents_mae: 13.6902 - val_confidence_loss: 7.3674e-06 - val_loss: 11.0834 - val_shift_cents_loss: 11.5728 - val_shift_cents_mae: 11.0834 - learning_rate: 0.0010\n",
      "Epoch 14/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 1.0783e-05 - loss: 13.6206 - shift_cents_loss: 13.6217 - shift_cents_mae: 13.6206 - val_confidence_loss: 2.9913e-06 - val_loss: 11.1364 - val_shift_cents_loss: 11.5487 - val_shift_cents_mae: 11.1364 - learning_rate: 0.0010\n",
      "Epoch 15/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 1.0783e-05 - loss: 13.6206 - shift_cents_loss: 13.6217 - shift_cents_mae: 13.6206 - val_confidence_loss: 2.9913e-06 - val_loss: 11.1364 - val_shift_cents_loss: 11.5487 - val_shift_cents_mae: 11.1364 - learning_rate: 0.0010\n",
      "Epoch 15/40\n",
      "\u001b[1m645/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - confidence_loss: 1.3957e-05 - loss: 9.1885 - shift_cents_loss: 9.1885 - shift_cents_mae: 9.1885\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 1.3213e-05 - loss: 13.5572 - shift_cents_loss: 13.5618 - shift_cents_mae: 13.5572 - val_confidence_loss: 2.0180e-06 - val_loss: 10.8456 - val_shift_cents_loss: 11.3679 - val_shift_cents_mae: 10.8456 - learning_rate: 0.0010\n",
      "Epoch 16/40\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 1.3213e-05 - loss: 13.5572 - shift_cents_loss: 13.5618 - shift_cents_mae: 13.5572 - val_confidence_loss: 2.0180e-06 - val_loss: 10.8456 - val_shift_cents_loss: 11.3679 - val_shift_cents_mae: 10.8456 - learning_rate: 0.0010\n",
      "Epoch 16/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 4.3112e-06 - loss: 13.3853 - shift_cents_loss: 13.3863 - shift_cents_mae: 13.3853 - val_confidence_loss: 3.4365e-07 - val_loss: 10.5528 - val_shift_cents_loss: 11.0436 - val_shift_cents_mae: 10.5528 - learning_rate: 5.0000e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 4.3112e-06 - loss: 13.3853 - shift_cents_loss: 13.3863 - shift_cents_mae: 13.3853 - val_confidence_loss: 3.4365e-07 - val_loss: 10.5528 - val_shift_cents_loss: 11.0436 - val_shift_cents_mae: 10.5528 - learning_rate: 5.0000e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 4.8244e-06 - loss: 13.3190 - shift_cents_loss: 13.3214 - shift_cents_mae: 13.3190 - val_confidence_loss: 4.1130e-06 - val_loss: 10.5932 - val_shift_cents_loss: 11.0451 - val_shift_cents_mae: 10.5932 - learning_rate: 5.0000e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 4.8244e-06 - loss: 13.3190 - shift_cents_loss: 13.3214 - shift_cents_mae: 13.3190 - val_confidence_loss: 4.1130e-06 - val_loss: 10.5932 - val_shift_cents_loss: 11.0451 - val_shift_cents_mae: 10.5932 - learning_rate: 5.0000e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 3.2583e-06 - loss: 13.2634 - shift_cents_loss: 13.2658 - shift_cents_mae: 13.2634 - val_confidence_loss: 5.0855e-07 - val_loss: 10.0871 - val_shift_cents_loss: 10.5386 - val_shift_cents_mae: 10.0871 - learning_rate: 5.0000e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 3.2583e-06 - loss: 13.2634 - shift_cents_loss: 13.2658 - shift_cents_mae: 13.2634 - val_confidence_loss: 5.0855e-07 - val_loss: 10.0871 - val_shift_cents_loss: 10.5386 - val_shift_cents_mae: 10.0871 - learning_rate: 5.0000e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 3.0059e-06 - loss: 13.2047 - shift_cents_loss: 13.2047 - shift_cents_mae: 13.2047 - val_confidence_loss: 9.5008e-07 - val_loss: 10.3935 - val_shift_cents_loss: 10.8716 - val_shift_cents_mae: 10.3935 - learning_rate: 5.0000e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 3.0059e-06 - loss: 13.2047 - shift_cents_loss: 13.2047 - shift_cents_mae: 13.2047 - val_confidence_loss: 9.5008e-07 - val_loss: 10.3935 - val_shift_cents_loss: 10.8716 - val_shift_cents_mae: 10.3935 - learning_rate: 5.0000e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 2.9707e-06 - loss: 13.1499 - shift_cents_loss: 13.1526 - shift_cents_mae: 13.1499 - val_confidence_loss: 2.4233e-06 - val_loss: 10.2644 - val_shift_cents_loss: 10.7197 - val_shift_cents_mae: 10.2644 - learning_rate: 5.0000e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 2.9707e-06 - loss: 13.1499 - shift_cents_loss: 13.1526 - shift_cents_mae: 13.1499 - val_confidence_loss: 2.4233e-06 - val_loss: 10.2644 - val_shift_cents_loss: 10.7197 - val_shift_cents_mae: 10.2644 - learning_rate: 5.0000e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m649/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - confidence_loss: 1.8578e-06 - loss: 8.8116 - shift_cents_loss: 8.8116 - shift_cents_mae: 8.8116\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 2.2389e-06 - loss: 13.1025 - shift_cents_loss: 13.1057 - shift_cents_mae: 13.1025 - val_confidence_loss: 1.1767e-06 - val_loss: 10.1491 - val_shift_cents_loss: 10.5841 - val_shift_cents_mae: 10.1491 - learning_rate: 5.0000e-04\n",
      "Epoch 22/40\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 2.2389e-06 - loss: 13.1025 - shift_cents_loss: 13.1057 - shift_cents_mae: 13.1025 - val_confidence_loss: 1.1767e-06 - val_loss: 10.1491 - val_shift_cents_loss: 10.5841 - val_shift_cents_mae: 10.1491 - learning_rate: 5.0000e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 1.3752e-06 - loss: 12.9618 - shift_cents_loss: 12.9651 - shift_cents_mae: 12.9618 - val_confidence_loss: 2.8093e-07 - val_loss: 9.9843 - val_shift_cents_loss: 10.4387 - val_shift_cents_mae: 9.9843 - learning_rate: 2.5000e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 1.3752e-06 - loss: 12.9618 - shift_cents_loss: 12.9651 - shift_cents_mae: 12.9618 - val_confidence_loss: 2.8093e-07 - val_loss: 9.9843 - val_shift_cents_loss: 10.4387 - val_shift_cents_mae: 9.9843 - learning_rate: 2.5000e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 1.1365e-06 - loss: 12.9200 - shift_cents_loss: 12.9211 - shift_cents_mae: 12.9200 - val_confidence_loss: 4.5760e-07 - val_loss: 9.9321 - val_shift_cents_loss: 10.3886 - val_shift_cents_mae: 9.9321 - learning_rate: 2.5000e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 1.1365e-06 - loss: 12.9200 - shift_cents_loss: 12.9211 - shift_cents_mae: 12.9200 - val_confidence_loss: 4.5760e-07 - val_loss: 9.9321 - val_shift_cents_loss: 10.3886 - val_shift_cents_mae: 9.9321 - learning_rate: 2.5000e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 9.3491e-07 - loss: 12.8792 - shift_cents_loss: 12.8797 - shift_cents_mae: 12.8792 - val_confidence_loss: 3.7872e-07 - val_loss: 9.5986 - val_shift_cents_loss: 10.0378 - val_shift_cents_mae: 9.5986 - learning_rate: 2.5000e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 9.3491e-07 - loss: 12.8792 - shift_cents_loss: 12.8797 - shift_cents_mae: 12.8792 - val_confidence_loss: 3.7872e-07 - val_loss: 9.5986 - val_shift_cents_loss: 10.0378 - val_shift_cents_mae: 9.5986 - learning_rate: 2.5000e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 7.6088e-07 - loss: 12.8420 - shift_cents_loss: 12.8425 - shift_cents_mae: 12.8420 - val_confidence_loss: 2.8669e-07 - val_loss: 9.6421 - val_shift_cents_loss: 10.0901 - val_shift_cents_mae: 9.6421 - learning_rate: 2.5000e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 7.6088e-07 - loss: 12.8420 - shift_cents_loss: 12.8425 - shift_cents_mae: 12.8420 - val_confidence_loss: 2.8669e-07 - val_loss: 9.6421 - val_shift_cents_loss: 10.0901 - val_shift_cents_mae: 9.6421 - learning_rate: 2.5000e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 7.2465e-07 - loss: 12.8135 - shift_cents_loss: 12.8162 - shift_cents_mae: 12.8135 - val_confidence_loss: 3.5911e-07 - val_loss: 9.8031 - val_shift_cents_loss: 10.2473 - val_shift_cents_mae: 9.8031 - learning_rate: 2.5000e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 7.2465e-07 - loss: 12.8135 - shift_cents_loss: 12.8162 - shift_cents_mae: 12.8135 - val_confidence_loss: 3.5911e-07 - val_loss: 9.8031 - val_shift_cents_loss: 10.2473 - val_shift_cents_mae: 9.8031 - learning_rate: 2.5000e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m648/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - confidence_loss: 3.8392e-07 - loss: 8.5739 - shift_cents_loss: 8.5739 - shift_cents_mae: 8.5739\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 5.8505e-07 - loss: 12.7861 - shift_cents_loss: 12.7856 - shift_cents_mae: 12.7861 - val_confidence_loss: 5.8143e-07 - val_loss: 9.6766 - val_shift_cents_loss: 10.1523 - val_shift_cents_mae: 9.6766 - learning_rate: 2.5000e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m  1/653\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - confidence_loss: 8.1002e-10 - loss: 6.4702 - shift_cents_loss: 6.4702 - shift_cents_mae: 6.4702\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 5.8505e-07 - loss: 12.7861 - shift_cents_loss: 12.7856 - shift_cents_mae: 12.7861 - val_confidence_loss: 5.8143e-07 - val_loss: 9.6766 - val_shift_cents_loss: 10.1523 - val_shift_cents_mae: 9.6766 - learning_rate: 2.5000e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 5.3563e-07 - loss: 12.7124 - shift_cents_loss: 12.7134 - shift_cents_mae: 12.7124 - val_confidence_loss: 6.8758e-07 - val_loss: 9.6298 - val_shift_cents_loss: 10.0746 - val_shift_cents_mae: 9.6298 - learning_rate: 1.2500e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 5.3563e-07 - loss: 12.7124 - shift_cents_loss: 12.7134 - shift_cents_mae: 12.7124 - val_confidence_loss: 6.8758e-07 - val_loss: 9.6298 - val_shift_cents_loss: 10.0746 - val_shift_cents_mae: 9.6298 - learning_rate: 1.2500e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 5.1521e-07 - loss: 12.6899 - shift_cents_loss: 12.6934 - shift_cents_mae: 12.6899 - val_confidence_loss: 3.0764e-07 - val_loss: 9.6476 - val_shift_cents_loss: 10.0954 - val_shift_cents_mae: 9.6476 - learning_rate: 1.2500e-04\n",
      "Epoch 30/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 5.1521e-07 - loss: 12.6899 - shift_cents_loss: 12.6934 - shift_cents_mae: 12.6899 - val_confidence_loss: 3.0764e-07 - val_loss: 9.6476 - val_shift_cents_loss: 10.0954 - val_shift_cents_mae: 9.6476 - learning_rate: 1.2500e-04\n",
      "Epoch 30/40\n",
      "\u001b[1m646/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - confidence_loss: 3.4007e-07 - loss: 8.5569 - shift_cents_loss: 8.5569 - shift_cents_mae: 8.5569\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 4.6739e-07 - loss: 12.6757 - shift_cents_loss: 12.6759 - shift_cents_mae: 12.6757 - val_confidence_loss: 4.1245e-07 - val_loss: 9.6750 - val_shift_cents_loss: 10.1256 - val_shift_cents_mae: 9.6750 - learning_rate: 1.2500e-04\n",
      "Epoch 31/40\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 4.6739e-07 - loss: 12.6757 - shift_cents_loss: 12.6759 - shift_cents_mae: 12.6757 - val_confidence_loss: 4.1245e-07 - val_loss: 9.6750 - val_shift_cents_loss: 10.1256 - val_shift_cents_mae: 9.6750 - learning_rate: 1.2500e-04\n",
      "Epoch 31/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 3.8463e-07 - loss: 12.6399 - shift_cents_loss: 12.6407 - shift_cents_mae: 12.6399 - val_confidence_loss: 6.0543e-07 - val_loss: 9.5760 - val_shift_cents_loss: 10.0440 - val_shift_cents_mae: 9.5760 - learning_rate: 6.2500e-05\n",
      "Epoch 32/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 3.8463e-07 - loss: 12.6399 - shift_cents_loss: 12.6407 - shift_cents_mae: 12.6399 - val_confidence_loss: 6.0543e-07 - val_loss: 9.5760 - val_shift_cents_loss: 10.0440 - val_shift_cents_mae: 9.5760 - learning_rate: 6.2500e-05\n",
      "Epoch 32/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 3.9646e-07 - loss: 12.6250 - shift_cents_loss: 12.6263 - shift_cents_mae: 12.6250 - val_confidence_loss: 6.6659e-07 - val_loss: 9.5249 - val_shift_cents_loss: 9.9890 - val_shift_cents_mae: 9.5249 - learning_rate: 6.2500e-05\n",
      "Epoch 33/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 3.9646e-07 - loss: 12.6250 - shift_cents_loss: 12.6263 - shift_cents_mae: 12.6250 - val_confidence_loss: 6.6659e-07 - val_loss: 9.5249 - val_shift_cents_loss: 9.9890 - val_shift_cents_mae: 9.5249 - learning_rate: 6.2500e-05\n",
      "Epoch 33/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 3.7978e-07 - loss: 12.6154 - shift_cents_loss: 12.6194 - shift_cents_mae: 12.6154 - val_confidence_loss: 5.6467e-07 - val_loss: 9.4853 - val_shift_cents_loss: 9.9493 - val_shift_cents_mae: 9.4853 - learning_rate: 6.2500e-05\n",
      "Epoch 34/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 3.7978e-07 - loss: 12.6154 - shift_cents_loss: 12.6194 - shift_cents_mae: 12.6154 - val_confidence_loss: 5.6467e-07 - val_loss: 9.4853 - val_shift_cents_loss: 9.9493 - val_shift_cents_mae: 9.4853 - learning_rate: 6.2500e-05\n",
      "Epoch 34/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 3.3768e-07 - loss: 12.6069 - shift_cents_loss: 12.6077 - shift_cents_mae: 12.6069 - val_confidence_loss: 5.6944e-07 - val_loss: 9.4712 - val_shift_cents_loss: 9.9368 - val_shift_cents_mae: 9.4712 - learning_rate: 6.2500e-05\n",
      "Epoch 35/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 3.3768e-07 - loss: 12.6069 - shift_cents_loss: 12.6077 - shift_cents_mae: 12.6069 - val_confidence_loss: 5.6944e-07 - val_loss: 9.4712 - val_shift_cents_loss: 9.9368 - val_shift_cents_mae: 9.4712 - learning_rate: 6.2500e-05\n",
      "Epoch 35/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 3.4370e-07 - loss: 12.5950 - shift_cents_loss: 12.5965 - shift_cents_mae: 12.5950 - val_confidence_loss: 5.4672e-07 - val_loss: 9.4929 - val_shift_cents_loss: 9.9515 - val_shift_cents_mae: 9.4929 - learning_rate: 6.2500e-05\n",
      "Epoch 36/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 3.4370e-07 - loss: 12.5950 - shift_cents_loss: 12.5965 - shift_cents_mae: 12.5950 - val_confidence_loss: 5.4672e-07 - val_loss: 9.4929 - val_shift_cents_loss: 9.9515 - val_shift_cents_mae: 9.4929 - learning_rate: 6.2500e-05\n",
      "Epoch 36/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 3.2234e-07 - loss: 12.5885 - shift_cents_loss: 12.5907 - shift_cents_mae: 12.5885 - val_confidence_loss: 5.2662e-07 - val_loss: 9.5025 - val_shift_cents_loss: 9.9638 - val_shift_cents_mae: 9.5025 - learning_rate: 6.2500e-05\n",
      "Epoch 37/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - confidence_loss: 3.2234e-07 - loss: 12.5885 - shift_cents_loss: 12.5907 - shift_cents_mae: 12.5885 - val_confidence_loss: 5.2662e-07 - val_loss: 9.5025 - val_shift_cents_loss: 9.9638 - val_shift_cents_mae: 9.5025 - learning_rate: 6.2500e-05\n",
      "Epoch 37/40\n",
      "\u001b[1m647/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - confidence_loss: 1.9657e-07 - loss: 8.3055 - shift_cents_loss: 8.3055 - shift_cents_mae: 8.3055\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 2.7064e-07 - loss: 12.5794 - shift_cents_loss: 12.5792 - shift_cents_mae: 12.5794 - val_confidence_loss: 4.2814e-07 - val_loss: 9.4942 - val_shift_cents_loss: 9.9539 - val_shift_cents_mae: 9.4942 - learning_rate: 6.2500e-05\n",
      "Epoch 38/40\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 2.7064e-07 - loss: 12.5794 - shift_cents_loss: 12.5792 - shift_cents_mae: 12.5794 - val_confidence_loss: 4.2814e-07 - val_loss: 9.4942 - val_shift_cents_loss: 9.9539 - val_shift_cents_mae: 9.4942 - learning_rate: 6.2500e-05\n",
      "Epoch 38/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 2.7434e-07 - loss: 12.5650 - shift_cents_loss: 12.5680 - shift_cents_mae: 12.5650 - val_confidence_loss: 4.1166e-07 - val_loss: 9.4952 - val_shift_cents_loss: 9.9592 - val_shift_cents_mae: 9.4952 - learning_rate: 3.1250e-05\n",
      "Epoch 39/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 2.7434e-07 - loss: 12.5650 - shift_cents_loss: 12.5680 - shift_cents_mae: 12.5650 - val_confidence_loss: 4.1166e-07 - val_loss: 9.4952 - val_shift_cents_loss: 9.9592 - val_shift_cents_mae: 9.4952 - learning_rate: 3.1250e-05\n",
      "Epoch 39/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 2.5970e-07 - loss: 12.5587 - shift_cents_loss: 12.5610 - shift_cents_mae: 12.5587 - val_confidence_loss: 4.5937e-07 - val_loss: 9.4993 - val_shift_cents_loss: 9.9622 - val_shift_cents_mae: 9.4993 - learning_rate: 3.1250e-05\n",
      "Epoch 40/40\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - confidence_loss: 2.5970e-07 - loss: 12.5587 - shift_cents_loss: 12.5610 - shift_cents_mae: 12.5587 - val_confidence_loss: 4.5937e-07 - val_loss: 9.4993 - val_shift_cents_loss: 9.9622 - val_shift_cents_mae: 9.4993 - learning_rate: 3.1250e-05\n",
      "Epoch 40/40\n",
      "\u001b[1m639/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - confidence_loss: 1.6289e-07 - loss: 8.2844 - shift_cents_loss: 8.2844 - shift_cents_mae: 8.2844\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 2.4405e-07 - loss: 12.5558 - shift_cents_loss: 12.5573 - shift_cents_mae: 12.5558 - val_confidence_loss: 4.4588e-07 - val_loss: 9.5127 - val_shift_cents_loss: 9.9700 - val_shift_cents_mae: 9.5127 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m653/653\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - confidence_loss: 2.4405e-07 - loss: 12.5558 - shift_cents_loss: 12.5573 - shift_cents_mae: 12.5558 - val_confidence_loss: 4.4588e-07 - val_loss: 9.5127 - val_shift_cents_loss: 9.9700 - val_shift_cents_mae: 9.5127 - learning_rate: 3.1250e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4) Training with curriculum hook (chromatic -> scale-aware)\n",
    "\n",
    "# packs the labels into a tuple of confidence and target shift\n",
    "def pack_labels(y):\n",
    "    conf = tf.ones_like(y, dtype=tf.float32)\n",
    "    return (y, conf)\n",
    "\n",
    "# reduces the learning rate on plateau and early stops if the validation loss does not improve\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_shift_cents_mae', mode='min', factor=0.5, patience=3, verbose=1),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_shift_cents_mae', mode='min', patience=7, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds.map(lambda x,y: (x, pack_labels(y))),\n",
    "    validation_data=(X_val, pack_labels(y_val)),\n",
    "    epochs=40,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(history.history['shift_cents_mae'], label='train MAE')\n",
    "plt.plot(history.history['val_shift_cents_mae'], label='val MAE')\n",
    "plt.legend(); plt.title('Cents MAE'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Emulator \n",
    "\n",
    " This section introduces the \"Streaming Emulator\", which simulates how the trained model would process audio input in a real-time, frame-by-frame (streaming) scenario. The emulator runs the model on one frame (feature vector) at a time, mimicking the constraints of live inference rather than batch processing. This is useful for testing how the model would behave in actual deployment on devices or applications that receive continuous audio input streams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming run frames: 501\n"
     ]
    }
   ],
   "source": [
    "# 5) Streaming emulator (per-hop inference)\n",
    "\n",
    "class StreamingEmulator:\n",
    "    def __init__(self, model, feature_mean, feature_std):\n",
    "        self.model = model\n",
    "        self.fm = feature_mean.astype(np.float32)\n",
    "        self.fs = feature_std.astype(np.float32)\n",
    "        self.buf = []\n",
    "\n",
    "    def step(self, frame):\n",
    "        frame = frame[:N_MELS]  # slice to first 32 mel-bins\n",
    "        frame = (frame - self.fm) / (self.fs + 1e-8)\n",
    "        self.buf.append(frame)\n",
    "        if len(self.buf) < 120:\n",
    "            return 0.0, 0.0  \n",
    "\n",
    "        if len(self.buf) > 120:\n",
    "            self.buf.pop(0)\n",
    "\n",
    "        x = np.array(self.buf, dtype=np.float32)[None, :, :] \n",
    "        shift, conf = self.model.predict(x, verbose=0)\n",
    "        return float(shift[0,0,0]), float(conf[0,0,0])\n",
    "\n",
    "# Example: run over first validation clip frame-by-frame\n",
    "if len(val_files) > 0:\n",
    "    arr = np.load(val_files[0])\n",
    "    frames = arr['logmel']\n",
    "    sim = StreamingEmulator(model, FEATURE_MEAN, FEATURE_STD)\n",
    "    out_shift = []\n",
    "    out_conf = []\n",
    "    for t in range(frames.shape[0]):\n",
    "        s,c = sim.step(frames[t])\n",
    "        out_shift.append(s); out_conf.append(c)\n",
    "    print('Streaming run frames:', len(out_shift))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 40, 32), dtype=tf.float32, name='features')\n",
      "Output Type:\n",
      "  Dict[['shift_cents', TensorSpec(shape=(None, 40, 1), dtype=tf.float32, name=None)], ['confidence', TensorSpec(shape=(None, 40, 1), dtype=tf.float32, name=None)]]\n",
      "Captures:\n",
      "  13366219728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13366220112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13366215120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13366216848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13366225488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362045840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362045264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362051408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362042960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362041040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362038544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362043344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362042384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362041616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13115108880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13115113296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13115111184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13115108304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13115112912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13115109456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "SavedModel exported to /Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model\n",
      "SavedModel exported to /Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1765359642.142451   14040 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1765359642.142462   14040 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-12-10 04:40:42.142638: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model\n",
      "2025-12-10 04:40:42.143656: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-12-10 04:40:42.143663: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model\n",
      "2025-12-10 04:40:42.156012: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-12-10 04:40:42.205864: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model\n",
      "2025-12-10 04:40:42.221129: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 78492 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model written.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 04:40:42.490549: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3705] Skipping runtime version metadata in the model. This will be generated by the exporter.\n"
     ]
    }
   ],
   "source": [
    "# 6) Export to SavedModel and TFLite (int8)\n",
    "\n",
    "export_dir = OUT_DIR / 'saved_model'\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sig_inputs = tf.keras.Input(shape=(WINDOW, N_MELS), name='features', dtype=tf.float32)\n",
    "sig_shift, sig_conf = model(sig_inputs)\n",
    "serve = tf.keras.Model(inputs=sig_inputs, outputs={'shift_cents': sig_shift, 'confidence': sig_conf})\n",
    "\n",
    "# Keras 3: export SavedModel for TFLite conversion\n",
    "serve.export(str(export_dir))\n",
    "print('SavedModel exported to', export_dir)\n",
    "\n",
    "# Representative dataset windows\n",
    "\n",
    "def rep_ds():\n",
    "    for _ in range(256):\n",
    "        i = np.random.randint(0, len(X_train))\n",
    "        x = X_train[i:i+1].astype(np.float32)\n",
    "        yield [x]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(str(export_dir))\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = rep_ds\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "(OUT_DIR / 'tflite').mkdir(parents=True, exist_ok=True)\n",
    "with open(OUT_DIR / 'tflite' / 'full_melody.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print('TFLite model written.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_output_name = OUT_DIR / 'tflite' / 'full_melody.tflite'\n",
    "cc_output_name = OUT_DIR / 'cc' / 'full_melody.cc'\n",
    "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
    "!xxd -i {tflite_output_name} > {cc_output_name}\n",
    "# Update variable names\n",
    "REPLACE_TEXT = str(tflite_output_name).replace('/', '_').replace('.', '_')\n",
    "!sed -i '' \"s/{REPLACE_TEXT}/g_full_melody_model_data/g\" {cc_output_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SavedModel (saved_model.pb) size: 144.3 KB\n",
      "TFLite quantized model size: 36.2 KB\n",
      "Size reduction: 74.9%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get file sizes\n",
    "saved_model_pb = export_dir / 'saved_model.pb'\n",
    "tflite_file = OUT_DIR / 'tflite' / 'full_melody.tflite'\n",
    "\n",
    "if saved_model_pb.exists():\n",
    "    saved_model_size = os.path.getsize(saved_model_pb)\n",
    "    print(f\"SavedModel (saved_model.pb) size: {saved_model_size / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(\"SavedModel (saved_model.pb) not found.\")\n",
    "\n",
    "if tflite_file.exists():\n",
    "    tflite_size = os.path.getsize(tflite_file)\n",
    "    print(f\"TFLite quantized model size: {tflite_size / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(\"TFLite model not found.\")\n",
    "\n",
    "if saved_model_pb.exists() and tflite_file.exists():\n",
    "    reduction = (1 - tflite_size / saved_model_size) * 100\n",
    "    print(f\"Size reduction: {reduction:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/25/wsswbv_57nq7kwz4csy0cm500000gn/T/tmpllndq4tp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/25/wsswbv_57nq7kwz4csy0cm500000gn/T/tmpllndq4tp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/25/wsswbv_57nq7kwz4csy0cm500000gn/T/tmpllndq4tp'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 40, 32), dtype=tf.float32, name='features')\n",
      "Output Type:\n",
      "  List[TensorSpec(shape=(None, 40, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 40, 1), dtype=tf.float32, name=None)]\n",
      "Captures:\n",
      "  13366219728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13366220112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13366215120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13366216848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13366225488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362045840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362045264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362051408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362042960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362041040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362038544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362043344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362042384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13362041616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13115108880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13115113296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13115111184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13115108304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13115112912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13115109456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "[{'index': 0, 'op_name': 'EXPAND_DIMS', 'inputs': array([ 0, 32], dtype=int32), 'outputs': array([33], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 1, 'op_name': 'CONV_2D', 'inputs': array([33, 21,  6], dtype=int32), 'outputs': array([34], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 2, 'op_name': 'RESHAPE', 'inputs': array([34, 10], dtype=int32), 'outputs': array([35], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 3, 'op_name': 'EXPAND_DIMS', 'inputs': array([35, 32], dtype=int32), 'outputs': array([36], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 4, 'op_name': 'CONV_2D', 'inputs': array([36, 20,  5], dtype=int32), 'outputs': array([37], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 5, 'op_name': 'RESHAPE', 'inputs': array([37, 10], dtype=int32), 'outputs': array([38], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 6, 'op_name': 'EXPAND_DIMS', 'inputs': array([38, 32], dtype=int32), 'outputs': array([39], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 7, 'op_name': 'CONV_2D', 'inputs': array([39, 19,  4], dtype=int32), 'outputs': array([40], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 8, 'op_name': 'RESHAPE', 'inputs': array([40, 10], dtype=int32), 'outputs': array([41], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 9, 'op_name': 'ADD', 'inputs': array([41, 35], dtype=int32), 'outputs': array([42], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 10, 'op_name': 'SPACE_TO_BATCH_ND', 'inputs': array([42, 31, 29], dtype=int32), 'outputs': array([43], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 11, 'op_name': 'EXPAND_DIMS', 'inputs': array([43, 32], dtype=int32), 'outputs': array([44], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 12, 'op_name': 'CONV_2D', 'inputs': array([44, 18, 22], dtype=int32), 'outputs': array([45], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 13, 'op_name': 'RESHAPE', 'inputs': array([45,  9], dtype=int32), 'outputs': array([46], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 14, 'op_name': 'BATCH_TO_SPACE_ND', 'inputs': array([46, 31, 30], dtype=int32), 'outputs': array([47], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 15, 'op_name': 'ADD', 'inputs': array([47, 25], dtype=int32), 'outputs': array([48], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 16, 'op_name': 'EXPAND_DIMS', 'inputs': array([48, 32], dtype=int32), 'outputs': array([49], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 17, 'op_name': 'CONV_2D', 'inputs': array([49, 17,  3], dtype=int32), 'outputs': array([50], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 18, 'op_name': 'RESHAPE', 'inputs': array([50, 10], dtype=int32), 'outputs': array([51], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 19, 'op_name': 'ADD', 'inputs': array([51, 42], dtype=int32), 'outputs': array([52], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 20, 'op_name': 'SPACE_TO_BATCH_ND', 'inputs': array([52, 28, 27], dtype=int32), 'outputs': array([53], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 21, 'op_name': 'EXPAND_DIMS', 'inputs': array([53, 32], dtype=int32), 'outputs': array([54], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 22, 'op_name': 'CONV_2D', 'inputs': array([54, 16, 22], dtype=int32), 'outputs': array([55], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 23, 'op_name': 'RESHAPE', 'inputs': array([55,  8], dtype=int32), 'outputs': array([56], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 24, 'op_name': 'BATCH_TO_SPACE_ND', 'inputs': array([56, 28, 30], dtype=int32), 'outputs': array([57], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 25, 'op_name': 'ADD', 'inputs': array([57, 24], dtype=int32), 'outputs': array([58], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 26, 'op_name': 'EXPAND_DIMS', 'inputs': array([58, 32], dtype=int32), 'outputs': array([59], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 27, 'op_name': 'CONV_2D', 'inputs': array([59, 15,  2], dtype=int32), 'outputs': array([60], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 28, 'op_name': 'RESHAPE', 'inputs': array([60, 10], dtype=int32), 'outputs': array([61], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 29, 'op_name': 'ADD', 'inputs': array([61, 52], dtype=int32), 'outputs': array([62], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 30, 'op_name': 'EXPAND_DIMS', 'inputs': array([62, 32], dtype=int32), 'outputs': array([63], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 31, 'op_name': 'CONV_2D', 'inputs': array([63, 14,  1], dtype=int32), 'outputs': array([64], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 32, 'op_name': 'RESHAPE', 'inputs': array([64, 10], dtype=int32), 'outputs': array([65], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 33, 'op_name': 'EXPAND_DIMS', 'inputs': array([65, 32], dtype=int32), 'outputs': array([66], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 34, 'op_name': 'CONV_2D', 'inputs': array([66, 12, 13], dtype=int32), 'outputs': array([67], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 35, 'op_name': 'RESHAPE', 'inputs': array([67,  7], dtype=int32), 'outputs': array([68], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 36, 'op_name': 'ADD', 'inputs': array([68, 26], dtype=int32), 'outputs': array([69], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 37, 'op_name': 'LOGISTIC', 'inputs': array([69], dtype=int32), 'outputs': array([70], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 38, 'op_name': 'CONV_2D', 'inputs': array([66, 11, 13], dtype=int32), 'outputs': array([71], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 39, 'op_name': 'RESHAPE', 'inputs': array([71,  7], dtype=int32), 'outputs': array([72], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 40, 'op_name': 'ADD', 'inputs': array([72, 23], dtype=int32), 'outputs': array([73], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 41, 'op_name': 'DELEGATE', 'inputs': array([ 6, 10, 21, 33], dtype=int32), 'outputs': array([35], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 42, 'op_name': 'DELEGATE', 'inputs': array([ 5, 10, 20, 36], dtype=int32), 'outputs': array([38], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 43, 'op_name': 'DELEGATE', 'inputs': array([ 4, 10, 19, 35, 39], dtype=int32), 'outputs': array([42], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 44, 'op_name': 'DELEGATE', 'inputs': array([ 9, 18, 22, 44], dtype=int32), 'outputs': array([46], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 45, 'op_name': 'DELEGATE', 'inputs': array([25, 47], dtype=int32), 'outputs': array([48], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 46, 'op_name': 'DELEGATE', 'inputs': array([ 3, 10, 17, 42, 49], dtype=int32), 'outputs': array([52], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 47, 'op_name': 'DELEGATE', 'inputs': array([ 8, 16, 22, 54], dtype=int32), 'outputs': array([56], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 48, 'op_name': 'DELEGATE', 'inputs': array([24, 57], dtype=int32), 'outputs': array([58], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 49, 'op_name': 'DELEGATE', 'inputs': array([ 2, 10, 15, 52, 59], dtype=int32), 'outputs': array([62], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 50, 'op_name': 'DELEGATE', 'inputs': array([ 1, 10, 14, 63], dtype=int32), 'outputs': array([65], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 51, 'op_name': 'DELEGATE', 'inputs': array([ 7, 11, 12, 13, 23, 26, 66], dtype=int32), 'outputs': array([70, 73], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>, <class 'numpy.float32'>]}]\n",
      "[{'index': 0, 'op_name': 'EXPAND_DIMS', 'inputs': array([ 0, 32], dtype=int32), 'outputs': array([33], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 1, 'op_name': 'CONV_2D', 'inputs': array([33, 21,  6], dtype=int32), 'outputs': array([34], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 2, 'op_name': 'RESHAPE', 'inputs': array([34, 10], dtype=int32), 'outputs': array([35], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 3, 'op_name': 'EXPAND_DIMS', 'inputs': array([35, 32], dtype=int32), 'outputs': array([36], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 4, 'op_name': 'CONV_2D', 'inputs': array([36, 20,  5], dtype=int32), 'outputs': array([37], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 5, 'op_name': 'RESHAPE', 'inputs': array([37, 10], dtype=int32), 'outputs': array([38], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 6, 'op_name': 'EXPAND_DIMS', 'inputs': array([38, 32], dtype=int32), 'outputs': array([39], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 7, 'op_name': 'CONV_2D', 'inputs': array([39, 19,  4], dtype=int32), 'outputs': array([40], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 8, 'op_name': 'RESHAPE', 'inputs': array([40, 10], dtype=int32), 'outputs': array([41], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 9, 'op_name': 'ADD', 'inputs': array([41, 35], dtype=int32), 'outputs': array([42], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 10, 'op_name': 'SPACE_TO_BATCH_ND', 'inputs': array([42, 31, 29], dtype=int32), 'outputs': array([43], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 11, 'op_name': 'EXPAND_DIMS', 'inputs': array([43, 32], dtype=int32), 'outputs': array([44], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 12, 'op_name': 'CONV_2D', 'inputs': array([44, 18, 22], dtype=int32), 'outputs': array([45], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 13, 'op_name': 'RESHAPE', 'inputs': array([45,  9], dtype=int32), 'outputs': array([46], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 14, 'op_name': 'BATCH_TO_SPACE_ND', 'inputs': array([46, 31, 30], dtype=int32), 'outputs': array([47], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 15, 'op_name': 'ADD', 'inputs': array([47, 25], dtype=int32), 'outputs': array([48], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 16, 'op_name': 'EXPAND_DIMS', 'inputs': array([48, 32], dtype=int32), 'outputs': array([49], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 17, 'op_name': 'CONV_2D', 'inputs': array([49, 17,  3], dtype=int32), 'outputs': array([50], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 18, 'op_name': 'RESHAPE', 'inputs': array([50, 10], dtype=int32), 'outputs': array([51], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 19, 'op_name': 'ADD', 'inputs': array([51, 42], dtype=int32), 'outputs': array([52], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 20, 'op_name': 'SPACE_TO_BATCH_ND', 'inputs': array([52, 28, 27], dtype=int32), 'outputs': array([53], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 21, 'op_name': 'EXPAND_DIMS', 'inputs': array([53, 32], dtype=int32), 'outputs': array([54], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 22, 'op_name': 'CONV_2D', 'inputs': array([54, 16, 22], dtype=int32), 'outputs': array([55], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 23, 'op_name': 'RESHAPE', 'inputs': array([55,  8], dtype=int32), 'outputs': array([56], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 24, 'op_name': 'BATCH_TO_SPACE_ND', 'inputs': array([56, 28, 30], dtype=int32), 'outputs': array([57], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 25, 'op_name': 'ADD', 'inputs': array([57, 24], dtype=int32), 'outputs': array([58], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 26, 'op_name': 'EXPAND_DIMS', 'inputs': array([58, 32], dtype=int32), 'outputs': array([59], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 27, 'op_name': 'CONV_2D', 'inputs': array([59, 15,  2], dtype=int32), 'outputs': array([60], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 28, 'op_name': 'RESHAPE', 'inputs': array([60, 10], dtype=int32), 'outputs': array([61], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 29, 'op_name': 'ADD', 'inputs': array([61, 52], dtype=int32), 'outputs': array([62], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 30, 'op_name': 'EXPAND_DIMS', 'inputs': array([62, 32], dtype=int32), 'outputs': array([63], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 31, 'op_name': 'CONV_2D', 'inputs': array([63, 14,  1], dtype=int32), 'outputs': array([64], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 32, 'op_name': 'RESHAPE', 'inputs': array([64, 10], dtype=int32), 'outputs': array([65], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 33, 'op_name': 'EXPAND_DIMS', 'inputs': array([65, 32], dtype=int32), 'outputs': array([66], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 34, 'op_name': 'CONV_2D', 'inputs': array([66, 12, 13], dtype=int32), 'outputs': array([67], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 35, 'op_name': 'RESHAPE', 'inputs': array([67,  7], dtype=int32), 'outputs': array([68], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 36, 'op_name': 'ADD', 'inputs': array([68, 26], dtype=int32), 'outputs': array([69], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 37, 'op_name': 'LOGISTIC', 'inputs': array([69], dtype=int32), 'outputs': array([70], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 38, 'op_name': 'CONV_2D', 'inputs': array([66, 11, 13], dtype=int32), 'outputs': array([71], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 39, 'op_name': 'RESHAPE', 'inputs': array([71,  7], dtype=int32), 'outputs': array([72], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 40, 'op_name': 'ADD', 'inputs': array([72, 23], dtype=int32), 'outputs': array([73], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 41, 'op_name': 'DELEGATE', 'inputs': array([ 6, 10, 21, 33], dtype=int32), 'outputs': array([35], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 42, 'op_name': 'DELEGATE', 'inputs': array([ 5, 10, 20, 36], dtype=int32), 'outputs': array([38], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 43, 'op_name': 'DELEGATE', 'inputs': array([ 4, 10, 19, 35, 39], dtype=int32), 'outputs': array([42], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 44, 'op_name': 'DELEGATE', 'inputs': array([ 9, 18, 22, 44], dtype=int32), 'outputs': array([46], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 45, 'op_name': 'DELEGATE', 'inputs': array([25, 47], dtype=int32), 'outputs': array([48], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 46, 'op_name': 'DELEGATE', 'inputs': array([ 3, 10, 17, 42, 49], dtype=int32), 'outputs': array([52], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 47, 'op_name': 'DELEGATE', 'inputs': array([ 8, 16, 22, 54], dtype=int32), 'outputs': array([56], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 48, 'op_name': 'DELEGATE', 'inputs': array([24, 57], dtype=int32), 'outputs': array([58], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 49, 'op_name': 'DELEGATE', 'inputs': array([ 2, 10, 15, 52, 59], dtype=int32), 'outputs': array([62], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 50, 'op_name': 'DELEGATE', 'inputs': array([ 1, 10, 14, 63], dtype=int32), 'outputs': array([65], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 51, 'op_name': 'DELEGATE', 'inputs': array([ 7, 11, 12, 13, 23, 26, 66], dtype=int32), 'outputs': array([70, 73], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>, <class 'numpy.float32'>]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1765359643.554083   14040 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1765359643.554094   14040 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-12-10 04:40:43.554211: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/25/wsswbv_57nq7kwz4csy0cm500000gn/T/tmpllndq4tp\n",
      "2025-12-10 04:40:43.554956: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-12-10 04:40:43.554963: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/25/wsswbv_57nq7kwz4csy0cm500000gn/T/tmpllndq4tp\n",
      "2025-12-10 04:40:43.564695: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-12-10 04:40:43.613097: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/25/wsswbv_57nq7kwz4csy0cm500000gn/T/tmpllndq4tp\n",
      "2025-12-10 04:40:43.627028: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 72817 microseconds.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite = converter.convert()\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "ops = interpreter.get_tensor_details()\n",
    "print(interpreter._get_ops_details())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
