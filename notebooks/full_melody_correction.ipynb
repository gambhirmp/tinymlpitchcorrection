{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notebook overview\n",
        "- Goal: train a tiny, streaming pitch‑correction model that predicts per‑frame shift (cents) and a confidence.\n",
        "- Strategy: build labels from a teacher (pYIN → low‑pass trend → hysteretic semitone snap), train a causal TCN on log‑mel features, export to int8 TFLite.\n",
        "- Sections:\n",
        "  1) Imports & config  \n",
        "  2) Data windowing/normalization \n",
        "  3) Causal TCN\n",
        "  4) Training (losses/callbacks)  \n",
        "  5) Streaming emulator  \n",
        "  6) SavedModel → TFLite\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full melody config: {'n_mels': 64, 'fps': 100}\n"
          ]
        }
      ],
      "source": [
        "# Full Melody Pitch Correction (Causal TCN, Streaming)\n",
        "\n",
        "# 1) Imports & Config\n",
        "import os, json, glob, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# directories for data access and artifacts\n",
        "ROOT = Path(\"/Users/brandontsai/ESE3600/tinymlpitchcorrection\")\n",
        "PROC_DIR = ROOT / \"data/processed/features\"\n",
        "META_DIR = ROOT / \"metadata\"\n",
        "OUT_DIR = ROOT / \"artifacts/full\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(META_DIR / \"feature_norm.json\", \"r\") as f:\n",
        "    norm = json.load(f)\n",
        "FEATURE_MEAN = np.array(norm[\"feature_mean\"] or [0.0]*64, dtype=np.float32)\n",
        "FEATURE_STD = np.array(norm[\"feature_std\"] or [1.0]*64, dtype=np.float32)\n",
        "FPS = norm.get(\"frames_per_second\", 100)\n",
        "\n",
        "N_MELS = 64 # can decrease to 32 for faster training/smaller model\n",
        "SHIFT_RANGE_CENTS = 300.0 # represents the range of possible pitch shifts\n",
        "\n",
        "random.seed(13)\n",
        "np.random.seed(13)\n",
        "tf.random.set_seed(13)\n",
        "print(\"Full melody config:\", dict(n_mels=N_MELS, fps=FPS))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: (9463, 120, 64) (9463, 120, 1) (292, 120, 64) (292, 120, 1)\n"
          ]
        }
      ],
      "source": [
        "# 2) Data loading (all categories), windowing, normalization\n",
        "\n",
        "def list_npz(split):\n",
        "    return sorted(glob.glob(str(PROC_DIR / split / '*.npz')))\n",
        "\n",
        "\n",
        "def normalize_features(x):\n",
        "    return (x - FEATURE_MEAN[None, :]) / (FEATURE_STD[None, :] + 1e-8)\n",
        "\n",
        "\n",
        "# makes sequences of features and targets\n",
        "def make_sequences(npz_paths, T=120, stride=60, limit=None):\n",
        "    xs, ys = [], []\n",
        "    count = 0\n",
        "    for p in npz_paths:\n",
        "        arr = np.load(p)\n",
        "        logmel = normalize_features(arr['logmel'].astype(np.float32))\n",
        "        target_shift = arr['target_shift'].astype(np.float32)\n",
        "        L = len(target_shift)\n",
        "        i = 0\n",
        "        while i + T <= L:\n",
        "            xs.append(logmel[i:i+T])\n",
        "            ys.append(target_shift[i:i+T, None])\n",
        "            i += stride\n",
        "            count += 1\n",
        "            if limit and count >= limit:\n",
        "                break\n",
        "        if limit and count >= limit:\n",
        "            break\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "train_files = list_npz('train')\n",
        "val_files = list_npz('val')\n",
        "X_train, y_train = make_sequences(train_files, T=120, stride=60)\n",
        "X_val, y_val = make_sequences(val_files, T=120, stride=60)\n",
        "print('Shapes:', X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
        "\n",
        "BATCH=32\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(4096).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ features            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ conv1d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ conv1d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ conv1d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ conv1d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ shift_cents         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ conv1d_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ confidence (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ conv1d_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ features            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m4,160\u001b[0m │ features[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m12,352\u001b[0m │ conv1d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m4,160\u001b[0m │ conv1d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ conv1d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m12,352\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_28 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m4,160\u001b[0m │ conv1d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_10 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m12,352\u001b[0m │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_30 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m4,160\u001b[0m │ conv1d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_11 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_31 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m4,160\u001b[0m │ add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ shift_cents         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │         \u001b[38;5;34m65\u001b[0m │ conv1d_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mConv1D\u001b[0m)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ confidence (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │         \u001b[38;5;34m65\u001b[0m │ conv1d_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,986</span> (226.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,986\u001b[0m (226.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,986</span> (226.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,986\u001b[0m (226.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 3) Causal TCN with dilations (causal Conv1D blocks)\n",
        "from tensorflow.keras import layers as L, models\n",
        "\n",
        "INPUT_DIM = N_MELS\n",
        "\n",
        "inp = L.Input(shape=(None, INPUT_DIM), name='features')\n",
        "x = L.Conv1D(64, 1, padding='same', activation='relu')(inp)\n",
        "\n",
        "# Residual dilated blocks (replace depthwise conv with causal Conv1D to avoid padding='causal' limitation)\n",
        "for d in [1, 2, 4]:\n",
        "    res = x\n",
        "    x = L.Conv1D(64, 3, dilation_rate=d, padding='same', activation=None)(x)\n",
        "    x = L.Conv1D(64, 1, activation='relu')(x)\n",
        "    x = L.Add()([x, res])\n",
        "\n",
        "x = L.Conv1D(64, 1, activation='relu')(x)\n",
        "shift = L.Conv1D(1, 1, activation=None, name='shift_cents')(x)\n",
        "conf = L.Conv1D(1, 1, activation='sigmoid', name='confidence')(x)\n",
        "\n",
        "model = models.Model(inputs=inp, outputs=[shift, conf])\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss={'shift_cents':'mae','confidence':'binary_crossentropy'},\n",
        "    loss_weights={'shift_cents':1.0,'confidence':0.01},\n",
        "    metrics={'shift_cents':'mae'}\n",
        ")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - confidence_loss: 0.1431 - loss: 16.2615 - shift_cents_loss: 16.2625 - shift_cents_mae: 16.2601 - val_confidence_loss: 0.0187 - val_loss: 12.6359 - val_shift_cents_loss: 13.8236 - val_shift_cents_mae: 12.6358 - learning_rate: 0.0010\n",
            "Epoch 2/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - confidence_loss: 0.0073 - loss: 15.1946 - shift_cents_loss: 15.1959 - shift_cents_mae: 15.1945 - val_confidence_loss: 0.0033 - val_loss: 11.6334 - val_shift_cents_loss: 12.6024 - val_shift_cents_mae: 11.6334 - learning_rate: 0.0010\n",
            "Epoch 3/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - confidence_loss: 0.0021 - loss: 14.0910 - shift_cents_loss: 14.0909 - shift_cents_mae: 14.0910 - val_confidence_loss: 0.0015 - val_loss: 10.7219 - val_shift_cents_loss: 11.7786 - val_shift_cents_mae: 10.7219 - learning_rate: 0.0010\n",
            "Epoch 4/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - confidence_loss: 0.0016 - loss: 12.9430 - shift_cents_loss: 12.9431 - shift_cents_mae: 12.9430 - val_confidence_loss: 0.0018 - val_loss: 9.8740 - val_shift_cents_loss: 10.7391 - val_shift_cents_mae: 9.8740 - learning_rate: 0.0010\n",
            "Epoch 5/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - confidence_loss: 0.0014 - loss: 12.2122 - shift_cents_loss: 12.2136 - shift_cents_mae: 12.2122 - val_confidence_loss: 0.0013 - val_loss: 9.3509 - val_shift_cents_loss: 10.0974 - val_shift_cents_mae: 9.3509 - learning_rate: 0.0010\n",
            "Epoch 6/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - confidence_loss: 9.9069e-04 - loss: 11.7043 - shift_cents_loss: 11.7095 - shift_cents_mae: 11.7043 - val_confidence_loss: 0.0010 - val_loss: 8.8674 - val_shift_cents_loss: 9.6251 - val_shift_cents_mae: 8.8674 - learning_rate: 0.0010\n",
            "Epoch 7/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - confidence_loss: 6.2670e-04 - loss: 11.3244 - shift_cents_loss: 11.3268 - shift_cents_mae: 11.3244 - val_confidence_loss: 5.4881e-04 - val_loss: 8.7792 - val_shift_cents_loss: 9.6724 - val_shift_cents_mae: 8.7792 - learning_rate: 0.0010\n",
            "Epoch 8/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - confidence_loss: 2.5825e-04 - loss: 11.1382 - shift_cents_loss: 11.1399 - shift_cents_mae: 11.1382 - val_confidence_loss: 3.4518e-04 - val_loss: 8.4278 - val_shift_cents_loss: 9.0889 - val_shift_cents_mae: 8.4277 - learning_rate: 0.0010\n",
            "Epoch 9/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - confidence_loss: 1.9000e-04 - loss: 10.9222 - shift_cents_loss: 10.9235 - shift_cents_mae: 10.9222 - val_confidence_loss: 1.5952e-04 - val_loss: 8.2633 - val_shift_cents_loss: 9.0518 - val_shift_cents_mae: 8.2633 - learning_rate: 0.0010\n",
            "Epoch 10/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - confidence_loss: 1.4294e-04 - loss: 10.6917 - shift_cents_loss: 10.6933 - shift_cents_mae: 10.6917 - val_confidence_loss: 2.3163e-04 - val_loss: 8.4068 - val_shift_cents_loss: 9.3113 - val_shift_cents_mae: 8.4068 - learning_rate: 0.0010\n",
            "Epoch 11/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - confidence_loss: 1.5705e-04 - loss: 10.5732 - shift_cents_loss: 10.5723 - shift_cents_mae: 10.5732 - val_confidence_loss: 8.9826e-05 - val_loss: 8.1497 - val_shift_cents_loss: 8.6781 - val_shift_cents_mae: 8.1497 - learning_rate: 0.0010\n",
            "Epoch 12/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - confidence_loss: 6.9776e-05 - loss: 10.4634 - shift_cents_loss: 10.4630 - shift_cents_mae: 10.4634 - val_confidence_loss: 1.2694e-04 - val_loss: 8.2700 - val_shift_cents_loss: 8.8388 - val_shift_cents_mae: 8.2700 - learning_rate: 0.0010\n",
            "Epoch 13/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - confidence_loss: 7.7387e-05 - loss: 10.3959 - shift_cents_loss: 10.3966 - shift_cents_mae: 10.3959 - val_confidence_loss: 1.3090e-04 - val_loss: 8.0038 - val_shift_cents_loss: 8.8028 - val_shift_cents_mae: 8.0038 - learning_rate: 0.0010\n",
            "Epoch 14/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - confidence_loss: 7.4100e-05 - loss: 10.3216 - shift_cents_loss: 10.3235 - shift_cents_mae: 10.3216 - val_confidence_loss: 8.2823e-05 - val_loss: 7.9899 - val_shift_cents_loss: 8.6245 - val_shift_cents_mae: 7.9899 - learning_rate: 0.0010\n",
            "Epoch 15/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - confidence_loss: 7.7574e-05 - loss: 10.2211 - shift_cents_loss: 10.2232 - shift_cents_mae: 10.2211 - val_confidence_loss: 1.4466e-04 - val_loss: 7.9756 - val_shift_cents_loss: 8.7132 - val_shift_cents_mae: 7.9756 - learning_rate: 0.0010\n",
            "Epoch 16/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - confidence_loss: 5.0994e-05 - loss: 10.1565 - shift_cents_loss: 10.1604 - shift_cents_mae: 10.1565 - val_confidence_loss: 7.0626e-05 - val_loss: 8.3377 - val_shift_cents_loss: 9.0659 - val_shift_cents_mae: 8.3377 - learning_rate: 0.0010\n",
            "Epoch 17/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - confidence_loss: 3.6317e-05 - loss: 10.0808 - shift_cents_loss: 10.0836 - shift_cents_mae: 10.0808 - val_confidence_loss: 7.3931e-05 - val_loss: 7.8831 - val_shift_cents_loss: 8.6077 - val_shift_cents_mae: 7.8831 - learning_rate: 0.0010\n",
            "Epoch 18/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - confidence_loss: 3.1055e-05 - loss: 9.9407 - shift_cents_loss: 9.9449 - shift_cents_mae: 9.9407 - val_confidence_loss: 1.1591e-04 - val_loss: 7.7880 - val_shift_cents_loss: 8.5898 - val_shift_cents_mae: 7.7880 - learning_rate: 0.0010\n",
            "Epoch 19/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - confidence_loss: 2.1077e-05 - loss: 9.9049 - shift_cents_loss: 9.9067 - shift_cents_mae: 9.9049 - val_confidence_loss: 2.0822e-05 - val_loss: 7.6444 - val_shift_cents_loss: 8.4427 - val_shift_cents_mae: 7.6444 - learning_rate: 0.0010\n",
            "Epoch 20/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - confidence_loss: 1.2972e-05 - loss: 9.8239 - shift_cents_loss: 9.8262 - shift_cents_mae: 9.8239 - val_confidence_loss: 5.5426e-05 - val_loss: 7.6015 - val_shift_cents_loss: 8.2937 - val_shift_cents_mae: 7.6015 - learning_rate: 0.0010\n",
            "Epoch 21/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - confidence_loss: 1.5464e-05 - loss: 9.7782 - shift_cents_loss: 9.7817 - shift_cents_mae: 9.7782 - val_confidence_loss: 6.0267e-05 - val_loss: 7.7820 - val_shift_cents_loss: 8.3489 - val_shift_cents_mae: 7.7820 - learning_rate: 0.0010\n",
            "Epoch 22/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - confidence_loss: 1.0637e-05 - loss: 9.7094 - shift_cents_loss: 9.7118 - shift_cents_mae: 9.7094 - val_confidence_loss: 1.9826e-05 - val_loss: 7.8688 - val_shift_cents_loss: 8.5264 - val_shift_cents_mae: 7.8688 - learning_rate: 0.0010\n",
            "Epoch 23/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - confidence_loss: 8.5672e-06 - loss: 9.6754 - shift_cents_loss: 9.6777 - shift_cents_mae: 9.6754 - val_confidence_loss: 2.8634e-05 - val_loss: 7.4458 - val_shift_cents_loss: 8.1366 - val_shift_cents_mae: 7.4458 - learning_rate: 0.0010\n",
            "Epoch 24/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - confidence_loss: 5.1776e-06 - loss: 9.6042 - shift_cents_loss: 9.6065 - shift_cents_mae: 9.6042 - val_confidence_loss: 3.0610e-05 - val_loss: 7.6098 - val_shift_cents_loss: 8.2002 - val_shift_cents_mae: 7.6098 - learning_rate: 0.0010\n",
            "Epoch 25/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - confidence_loss: 5.8411e-06 - loss: 9.5802 - shift_cents_loss: 9.5799 - shift_cents_mae: 9.5802 - val_confidence_loss: 1.4250e-05 - val_loss: 7.9646 - val_shift_cents_loss: 8.5911 - val_shift_cents_mae: 7.9646 - learning_rate: 0.0010\n",
            "Epoch 26/40\n",
            "\u001b[1m295/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - confidence_loss: 6.4322e-06 - loss: 7.5441 - shift_cents_loss: 7.5441 - shift_cents_mae: 7.5441\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - confidence_loss: 6.5459e-06 - loss: 9.5615 - shift_cents_loss: 9.5656 - shift_cents_mae: 9.5615 - val_confidence_loss: 4.7820e-05 - val_loss: 7.5136 - val_shift_cents_loss: 8.1440 - val_shift_cents_mae: 7.5136 - learning_rate: 0.0010\n",
            "Epoch 27/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - confidence_loss: 5.0624e-06 - loss: 9.1889 - shift_cents_loss: 9.1918 - shift_cents_mae: 9.1889 - val_confidence_loss: 2.5467e-05 - val_loss: 7.3210 - val_shift_cents_loss: 8.0310 - val_shift_cents_mae: 7.3210 - learning_rate: 5.0000e-04\n",
            "Epoch 28/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - confidence_loss: 3.8410e-06 - loss: 9.1165 - shift_cents_loss: 9.1182 - shift_cents_mae: 9.1165 - val_confidence_loss: 2.0970e-05 - val_loss: 7.0647 - val_shift_cents_loss: 7.6453 - val_shift_cents_mae: 7.0647 - learning_rate: 5.0000e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - confidence_loss: 2.8709e-06 - loss: 9.1039 - shift_cents_loss: 9.1053 - shift_cents_mae: 9.1039 - val_confidence_loss: 1.6252e-05 - val_loss: 7.1993 - val_shift_cents_loss: 7.9011 - val_shift_cents_mae: 7.1993 - learning_rate: 5.0000e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - confidence_loss: 2.1128e-06 - loss: 9.0523 - shift_cents_loss: 9.0560 - shift_cents_mae: 9.0523 - val_confidence_loss: 5.3598e-06 - val_loss: 7.2683 - val_shift_cents_loss: 7.9964 - val_shift_cents_mae: 7.2683 - learning_rate: 5.0000e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m292/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - confidence_loss: 1.9535e-06 - loss: 7.0767 - shift_cents_loss: 7.0767 - shift_cents_mae: 7.0767\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - confidence_loss: 2.1163e-06 - loss: 9.0234 - shift_cents_loss: 9.0259 - shift_cents_mae: 9.0234 - val_confidence_loss: 8.8354e-06 - val_loss: 7.2071 - val_shift_cents_loss: 7.9004 - val_shift_cents_mae: 7.2071 - learning_rate: 5.0000e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - confidence_loss: 1.8399e-06 - loss: 8.8380 - shift_cents_loss: 8.8400 - shift_cents_mae: 8.8380 - val_confidence_loss: 6.8750e-06 - val_loss: 7.0013 - val_shift_cents_loss: 7.6819 - val_shift_cents_mae: 7.0013 - learning_rate: 2.5000e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - confidence_loss: 1.4236e-06 - loss: 8.7989 - shift_cents_loss: 8.7998 - shift_cents_mae: 8.7989 - val_confidence_loss: 4.4238e-06 - val_loss: 7.0394 - val_shift_cents_loss: 7.7783 - val_shift_cents_mae: 7.0394 - learning_rate: 2.5000e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - confidence_loss: 1.2061e-06 - loss: 8.7819 - shift_cents_loss: 8.7848 - shift_cents_mae: 8.7819 - val_confidence_loss: 4.4711e-06 - val_loss: 7.0218 - val_shift_cents_loss: 7.7568 - val_shift_cents_mae: 7.0218 - learning_rate: 2.5000e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - confidence_loss: 9.7238e-07 - loss: 8.7660 - shift_cents_loss: 8.7658 - shift_cents_mae: 8.7660 - val_confidence_loss: 2.8971e-06 - val_loss: 6.9787 - val_shift_cents_loss: 7.6896 - val_shift_cents_mae: 6.9787 - learning_rate: 2.5000e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - confidence_loss: 8.5900e-07 - loss: 8.7377 - shift_cents_loss: 8.7418 - shift_cents_mae: 8.7377 - val_confidence_loss: 2.3675e-06 - val_loss: 7.0639 - val_shift_cents_loss: 7.8136 - val_shift_cents_mae: 7.0639 - learning_rate: 2.5000e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - confidence_loss: 8.0896e-07 - loss: 8.7205 - shift_cents_loss: 8.7251 - shift_cents_mae: 8.7205 - val_confidence_loss: 2.5537e-06 - val_loss: 6.9861 - val_shift_cents_loss: 7.6904 - val_shift_cents_mae: 6.9861 - learning_rate: 2.5000e-04\n",
            "Epoch 38/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - confidence_loss: 7.3398e-07 - loss: 6.8789 - shift_cents_loss: 6.8789 - shift_cents_mae: 6.8789\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - confidence_loss: 6.2748e-07 - loss: 8.7058 - shift_cents_loss: 8.7079 - shift_cents_mae: 8.7058 - val_confidence_loss: 2.3018e-06 - val_loss: 6.9788 - val_shift_cents_loss: 7.7309 - val_shift_cents_mae: 6.9788 - learning_rate: 2.5000e-04\n",
            "Epoch 39/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - confidence_loss: 6.6397e-07 - loss: 8.6032 - shift_cents_loss: 8.6028 - shift_cents_mae: 8.6032 - val_confidence_loss: 1.6858e-06 - val_loss: 6.9475 - val_shift_cents_loss: 7.6790 - val_shift_cents_mae: 6.9475 - learning_rate: 1.2500e-04\n",
            "Epoch 40/40\n",
            "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - confidence_loss: 5.4807e-07 - loss: 8.5855 - shift_cents_loss: 8.5850 - shift_cents_mae: 8.5855 - val_confidence_loss: 2.5136e-06 - val_loss: 6.8995 - val_shift_cents_loss: 7.6011 - val_shift_cents_mae: 6.8995 - learning_rate: 1.2500e-04\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 4) Training with curriculum hook (chromatic -> scale-aware)\n",
        "\n",
        "# packs the labels into a tuple of confidence and target shift\n",
        "def pack_labels(y):\n",
        "    conf = tf.ones_like(y, dtype=tf.float32)\n",
        "    return (y, conf)\n",
        "\n",
        "# reduces the learning rate on plateau and early stops if the validation loss does not improve\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_shift_cents_mae', mode='min', factor=0.5, patience=3, verbose=1),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_shift_cents_mae', mode='min', patience=7, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds.map(lambda x,y: (x, pack_labels(y))),\n",
        "    validation_data=(X_val, pack_labels(y_val)),\n",
        "    epochs=40,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.plot(history.history['shift_cents_mae'], label='train MAE')\n",
        "plt.plot(history.history['val_shift_cents_mae'], label='val MAE')\n",
        "plt.legend(); plt.title('Cents MAE'); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Streaming Emulator \n",
        "\n",
        " This section introduces the \"Streaming Emulator\", which simulates how the trained model would process audio input in a real-time, frame-by-frame (streaming) scenario. The emulator runs the model on one frame (feature vector) at a time, mimicking the constraints of live inference rather than batch processing. This is useful for testing how the model would behave in actual deployment on devices or applications that receive continuous audio input streams.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'StreamingEmulator' object has no attribute 'buf'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m out_conf \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(frames\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 30\u001b[0m     s,c \u001b[38;5;241m=\u001b[39m \u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     out_shift\u001b[38;5;241m.\u001b[39mappend(s); out_conf\u001b[38;5;241m.\u001b[39mappend(c)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStreaming run frames:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(out_shift))\n",
            "Cell \u001b[0;32mIn[25], line 11\u001b[0m, in \u001b[0;36mStreamingEmulator.step\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame):\n\u001b[1;32m     10\u001b[0m     frame \u001b[38;5;241m=\u001b[39m (frame \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfm) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuf\u001b[49m\u001b[38;5;241m.\u001b[39mappend(frame)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m120\u001b[39m:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m  \n",
            "\u001b[0;31mAttributeError\u001b[0m: 'StreamingEmulator' object has no attribute 'buf'"
          ]
        }
      ],
      "source": [
        "# 5) Streaming emulator (per-hop inference)\n",
        "\n",
        "class StreamingEmulator:\n",
        "    def __init__(self, model, feature_mean, feature_std):\n",
        "        self.model = model\n",
        "        self.fm = feature_mean.astype(np.float32)\n",
        "        self.fs = feature_std.astype(np.float32)\n",
        "\n",
        "    def step(self, frame):\n",
        "        frame = (frame - self.fm) / (self.fs + 1e-8)\n",
        "        self.buf.append(frame)\n",
        "        if len(self.buf) < 120:\n",
        "            return 0.0, 0.0  \n",
        "\n",
        "        if len(self.buf) > 120:\n",
        "            self.buf.pop(0)\n",
        "\n",
        "        x = np.array(self.buf, dtype=np.float32)[None, :, :] \n",
        "        shift, conf = self.model.predict(x, verbose=0)\n",
        "        return float(shift[0,0,0]), float(conf[0,0,0])\n",
        "\n",
        "# Example: run over first validation clip frame-by-frame\n",
        "if len(val_files) > 0:\n",
        "    arr = np.load(val_files[0])\n",
        "    frames = arr['logmel']\n",
        "    sim = StreamingEmulator(model, FEATURE_MEAN, FEATURE_STD)\n",
        "    out_shift = []\n",
        "    out_conf = []\n",
        "    for t in range(frames.shape[0]):\n",
        "        s,c = sim.step(frames[t])\n",
        "        out_shift.append(s); out_conf.append(c)\n",
        "    print('Streaming run frames:', len(out_shift))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, None, 64), dtype=tf.float32, name='features')\n",
            "Output Type:\n",
            "  Dict[['shift_cents', TensorSpec(shape=(None, None, 1), dtype=tf.float32, name=None)], ['confidence', TensorSpec(shape=(None, None, 1), dtype=tf.float32, name=None)]]\n",
            "Captures:\n",
            "  4434867216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072243536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072242576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072243152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072240272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072240080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072242768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072242960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690716688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690706512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690710928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690707088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690707664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690710544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690721872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690711504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690710160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690708240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690716496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690711888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "SavedModel exported to /Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1765332870.090141 19157689 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "W0000 00:00:1765332870.090319 19157689 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-12-09 21:14:30.090487: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model\n",
            "2025-12-09 21:14:30.091400: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2025-12-09 21:14:30.091406: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model\n",
            "2025-12-09 21:14:30.100742: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2025-12-09 21:14:30.141820: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /Users/brandontsai/ESE3600/tinymlpitchcorrection/artifacts/full/saved_model\n",
            "2025-12-09 21:14:30.157087: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 66602 microseconds.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TFLite model written.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
            "2025-12-09 21:14:32.137970: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3705] Skipping runtime version metadata in the model. This will be generated by the exporter.\n"
          ]
        }
      ],
      "source": [
        "# 6) Export to SavedModel and TFLite (int8)\n",
        "\n",
        "export_dir = OUT_DIR / 'saved_model'\n",
        "export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "sig_inputs = tf.keras.Input(shape=(None, N_MELS), name='features', dtype=tf.float32)\n",
        "sig_shift, sig_conf = model(sig_inputs)\n",
        "serve = tf.keras.Model(inputs=sig_inputs, outputs={'shift_cents': sig_shift, 'confidence': sig_conf})\n",
        "\n",
        "# Keras 3: export SavedModel for TFLite conversion\n",
        "serve.export(str(export_dir))\n",
        "print('SavedModel exported to', export_dir)\n",
        "\n",
        "# Representative dataset windows\n",
        "\n",
        "def rep_ds():\n",
        "    for _ in range(256):\n",
        "        i = np.random.randint(0, len(X_train))\n",
        "        x = X_train[i:i+1].astype(np.float32)\n",
        "        yield [x]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(str(export_dir))\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = rep_ds\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "(OUT_DIR / 'tflite').mkdir(parents=True, exist_ok=True)\n",
        "with open(OUT_DIR / 'tflite' / 'full_melody.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "print('TFLite model written.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tflite_output_name = OUT_DIR / 'tflite' / 'full_melody.tflite'\n",
        "cc_output_name = OUT_DIR / 'cc' / 'full_melody.cc'\n",
        "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
        "!xxd -i {tflite_output_name} > {cc_output_name}\n",
        "# Update variable names\n",
        "REPLACE_TEXT = str(tflite_output_name).replace('/', '_').replace('.', '_')\n",
        "!sed -i '' \"s/{REPLACE_TEXT}/g_full_melody_model_data/g\" {cc_output_name}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/25/wsswbv_57nq7kwz4csy0cm500000gn/T/tmp30n3859_/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/25/wsswbv_57nq7kwz4csy0cm500000gn/T/tmp30n3859_/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/var/folders/25/wsswbv_57nq7kwz4csy0cm500000gn/T/tmp30n3859_'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, None, 64), dtype=tf.float32, name='features')\n",
            "Output Type:\n",
            "  List[TensorSpec(shape=(None, None, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float32, name=None)]\n",
            "Captures:\n",
            "  4434867216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072243536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072242576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072243152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072240272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072240080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072242768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  13072242960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690716688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690706512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690710928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690707088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690707664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690710544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690721872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690711504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690710160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690708240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690716496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  4690711888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "[{'index': 0, 'op_name': 'EXPAND_DIMS', 'inputs': array([ 0, 34], dtype=int32), 'outputs': array([35], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 1, 'op_name': 'CONV_2D', 'inputs': array([35, 13, 14], dtype=int32), 'outputs': array([36], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 2, 'op_name': 'SQUEEZE', 'inputs': array([36], dtype=int32), 'outputs': array([37], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 3, 'op_name': 'ADD', 'inputs': array([37, 23], dtype=int32), 'outputs': array([38], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 4, 'op_name': 'PAD', 'inputs': array([38, 30], dtype=int32), 'outputs': array([39], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 5, 'op_name': 'EXPAND_DIMS', 'inputs': array([39, 34], dtype=int32), 'outputs': array([40], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 6, 'op_name': 'CONV_2D', 'inputs': array([40, 12, 14], dtype=int32), 'outputs': array([41], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 7, 'op_name': 'SQUEEZE', 'inputs': array([41], dtype=int32), 'outputs': array([42], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 8, 'op_name': 'ADD', 'inputs': array([42, 22], dtype=int32), 'outputs': array([43], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 9, 'op_name': 'EXPAND_DIMS', 'inputs': array([43, 34], dtype=int32), 'outputs': array([44], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 10, 'op_name': 'CONV_2D', 'inputs': array([44, 11, 14], dtype=int32), 'outputs': array([45], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 11, 'op_name': 'SQUEEZE', 'inputs': array([45], dtype=int32), 'outputs': array([46], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 12, 'op_name': 'ADD', 'inputs': array([46, 21], dtype=int32), 'outputs': array([47], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 13, 'op_name': 'ADD', 'inputs': array([47, 38], dtype=int32), 'outputs': array([48], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 14, 'op_name': 'PAD', 'inputs': array([48, 29], dtype=int32), 'outputs': array([49], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 15, 'op_name': 'SHAPE', 'inputs': array([49], dtype=int32), 'outputs': array([50], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 16, 'op_name': 'STRIDED_SLICE', 'inputs': array([50, 32, 33, 32], dtype=int32), 'outputs': array([51], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 17, 'op_name': 'RESHAPE', 'inputs': array([51, 32], dtype=int32), 'outputs': array([52], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 18, 'op_name': 'FLOOR_MOD', 'inputs': array([52, 33], dtype=int32), 'outputs': array([53], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 19, 'op_name': 'SUB', 'inputs': array([33, 53], dtype=int32), 'outputs': array([54], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 20, 'op_name': 'FLOOR_MOD', 'inputs': array([54, 33], dtype=int32), 'outputs': array([55], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 21, 'op_name': 'STRIDED_SLICE', 'inputs': array([55, 27, 32, 32], dtype=int32), 'outputs': array([56], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 22, 'op_name': 'PACK', 'inputs': array([26, 56], dtype=int32), 'outputs': array([57], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 23, 'op_name': 'RESHAPE', 'inputs': array([57, 25], dtype=int32), 'outputs': array([58], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 24, 'op_name': 'STRIDED_SLICE', 'inputs': array([58, 10, 25,  9], dtype=int32), 'outputs': array([59], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 25, 'op_name': 'SPACE_TO_BATCH_ND', 'inputs': array([49, 33, 59], dtype=int32), 'outputs': array([60], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 26, 'op_name': 'EXPAND_DIMS', 'inputs': array([60, 34], dtype=int32), 'outputs': array([61], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 27, 'op_name': 'CONV_2D', 'inputs': array([61,  8, 14], dtype=int32), 'outputs': array([62], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 28, 'op_name': 'SQUEEZE', 'inputs': array([62], dtype=int32), 'outputs': array([63], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 29, 'op_name': 'BATCH_TO_SPACE_ND', 'inputs': array([63, 33, 59], dtype=int32), 'outputs': array([64], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 30, 'op_name': 'ADD', 'inputs': array([64, 20], dtype=int32), 'outputs': array([65], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 31, 'op_name': 'EXPAND_DIMS', 'inputs': array([65, 34], dtype=int32), 'outputs': array([66], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 32, 'op_name': 'CONV_2D', 'inputs': array([66,  7, 14], dtype=int32), 'outputs': array([67], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 33, 'op_name': 'SQUEEZE', 'inputs': array([67], dtype=int32), 'outputs': array([68], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 34, 'op_name': 'ADD', 'inputs': array([68, 19], dtype=int32), 'outputs': array([69], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 35, 'op_name': 'ADD', 'inputs': array([69, 48], dtype=int32), 'outputs': array([70], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 36, 'op_name': 'PAD', 'inputs': array([70, 28], dtype=int32), 'outputs': array([71], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 37, 'op_name': 'SHAPE', 'inputs': array([71], dtype=int32), 'outputs': array([72], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 38, 'op_name': 'STRIDED_SLICE', 'inputs': array([72, 32, 33, 32], dtype=int32), 'outputs': array([73], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 39, 'op_name': 'RESHAPE', 'inputs': array([73, 32], dtype=int32), 'outputs': array([74], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 40, 'op_name': 'FLOOR_MOD', 'inputs': array([74, 31], dtype=int32), 'outputs': array([75], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 41, 'op_name': 'SUB', 'inputs': array([31, 75], dtype=int32), 'outputs': array([76], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 42, 'op_name': 'FLOOR_MOD', 'inputs': array([76, 31], dtype=int32), 'outputs': array([77], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 43, 'op_name': 'STRIDED_SLICE', 'inputs': array([77, 27, 32, 32], dtype=int32), 'outputs': array([78], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 44, 'op_name': 'PACK', 'inputs': array([26, 78], dtype=int32), 'outputs': array([79], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 45, 'op_name': 'RESHAPE', 'inputs': array([79, 25], dtype=int32), 'outputs': array([80], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 46, 'op_name': 'STRIDED_SLICE', 'inputs': array([80, 10, 25,  9], dtype=int32), 'outputs': array([81], dtype=int32), 'operand_types': [<class 'numpy.int32'>, <class 'numpy.int32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.int32'>]}, {'index': 47, 'op_name': 'SPACE_TO_BATCH_ND', 'inputs': array([71, 31, 81], dtype=int32), 'outputs': array([82], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 48, 'op_name': 'EXPAND_DIMS', 'inputs': array([82, 34], dtype=int32), 'outputs': array([83], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 49, 'op_name': 'CONV_2D', 'inputs': array([83,  6, 14], dtype=int32), 'outputs': array([84], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 50, 'op_name': 'SQUEEZE', 'inputs': array([84], dtype=int32), 'outputs': array([85], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 51, 'op_name': 'BATCH_TO_SPACE_ND', 'inputs': array([85, 31, 81], dtype=int32), 'outputs': array([86], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 52, 'op_name': 'ADD', 'inputs': array([86, 18], dtype=int32), 'outputs': array([87], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 53, 'op_name': 'EXPAND_DIMS', 'inputs': array([87, 34], dtype=int32), 'outputs': array([88], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 54, 'op_name': 'CONV_2D', 'inputs': array([88,  5, 14], dtype=int32), 'outputs': array([89], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 55, 'op_name': 'SQUEEZE', 'inputs': array([89], dtype=int32), 'outputs': array([90], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 56, 'op_name': 'ADD', 'inputs': array([90, 17], dtype=int32), 'outputs': array([91], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 57, 'op_name': 'ADD', 'inputs': array([91, 70], dtype=int32), 'outputs': array([92], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 58, 'op_name': 'EXPAND_DIMS', 'inputs': array([92, 34], dtype=int32), 'outputs': array([93], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 59, 'op_name': 'CONV_2D', 'inputs': array([93,  4, 14], dtype=int32), 'outputs': array([94], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 60, 'op_name': 'SQUEEZE', 'inputs': array([94], dtype=int32), 'outputs': array([95], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 61, 'op_name': 'ADD', 'inputs': array([95, 16], dtype=int32), 'outputs': array([96], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 62, 'op_name': 'EXPAND_DIMS', 'inputs': array([96, 34], dtype=int32), 'outputs': array([97], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 63, 'op_name': 'CONV_2D', 'inputs': array([97,  2,  3], dtype=int32), 'outputs': array([98], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 64, 'op_name': 'SQUEEZE', 'inputs': array([98], dtype=int32), 'outputs': array([99], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 65, 'op_name': 'ADD', 'inputs': array([99, 24], dtype=int32), 'outputs': array([100], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 66, 'op_name': 'LOGISTIC', 'inputs': array([100], dtype=int32), 'outputs': array([101], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 67, 'op_name': 'CONV_2D', 'inputs': array([97,  1,  3], dtype=int32), 'outputs': array([102], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 68, 'op_name': 'SQUEEZE', 'inputs': array([102], dtype=int32), 'outputs': array([103], dtype=int32), 'operand_types': [<class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 69, 'op_name': 'ADD', 'inputs': array([103,  15], dtype=int32), 'outputs': array([104], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 70, 'op_name': 'DELEGATE', 'inputs': array([13, 14, 35], dtype=int32), 'outputs': array([36], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 71, 'op_name': 'DELEGATE', 'inputs': array([23, 30, 37], dtype=int32), 'outputs': array([38, 39], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>, <class 'numpy.float32'>]}, {'index': 72, 'op_name': 'DELEGATE', 'inputs': array([12, 14, 40], dtype=int32), 'outputs': array([41], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 73, 'op_name': 'DELEGATE', 'inputs': array([22, 42], dtype=int32), 'outputs': array([43], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 74, 'op_name': 'DELEGATE', 'inputs': array([11, 14, 44], dtype=int32), 'outputs': array([45], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 75, 'op_name': 'DELEGATE', 'inputs': array([21, 29, 38, 46], dtype=int32), 'outputs': array([48, 49], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>, <class 'numpy.float32'>]}, {'index': 76, 'op_name': 'DELEGATE', 'inputs': array([ 8, 14, 61], dtype=int32), 'outputs': array([62], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 77, 'op_name': 'DELEGATE', 'inputs': array([20, 64], dtype=int32), 'outputs': array([65], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 78, 'op_name': 'DELEGATE', 'inputs': array([ 7, 14, 66], dtype=int32), 'outputs': array([67], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 79, 'op_name': 'DELEGATE', 'inputs': array([19, 28, 48, 68], dtype=int32), 'outputs': array([70, 71], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.int32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>, <class 'numpy.float32'>]}, {'index': 80, 'op_name': 'DELEGATE', 'inputs': array([ 6, 14, 83], dtype=int32), 'outputs': array([84], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 81, 'op_name': 'DELEGATE', 'inputs': array([18, 86], dtype=int32), 'outputs': array([87], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 82, 'op_name': 'DELEGATE', 'inputs': array([ 5, 14, 88], dtype=int32), 'outputs': array([89], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 83, 'op_name': 'DELEGATE', 'inputs': array([17, 70, 90], dtype=int32), 'outputs': array([92], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 84, 'op_name': 'DELEGATE', 'inputs': array([ 4, 14, 93], dtype=int32), 'outputs': array([94], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 85, 'op_name': 'DELEGATE', 'inputs': array([16, 95], dtype=int32), 'outputs': array([96], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>]}, {'index': 86, 'op_name': 'DELEGATE', 'inputs': array([ 1,  2,  3, 97], dtype=int32), 'outputs': array([ 98, 102], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>, <class 'numpy.float32'>]}, {'index': 87, 'op_name': 'DELEGATE', 'inputs': array([ 15,  24,  99, 103], dtype=int32), 'outputs': array([101, 104], dtype=int32), 'operand_types': [<class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>, <class 'numpy.float32'>], 'result_types': [<class 'numpy.float32'>, <class 'numpy.float32'>]}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1765332873.378783 19157689 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "W0000 00:00:1765332873.378798 19157689 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-12-09 21:14:33.378916: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/25/wsswbv_57nq7kwz4csy0cm500000gn/T/tmp30n3859_\n",
            "2025-12-09 21:14:33.379688: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2025-12-09 21:14:33.379694: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/25/wsswbv_57nq7kwz4csy0cm500000gn/T/tmp30n3859_\n",
            "2025-12-09 21:14:33.390243: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2025-12-09 21:14:33.432112: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/25/wsswbv_57nq7kwz4csy0cm500000gn/T/tmp30n3859_\n",
            "2025-12-09 21:14:33.449766: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 70850 microseconds.\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite = converter.convert()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "ops = interpreter.get_tensor_details()\n",
        "print(interpreter._get_ops_details())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
